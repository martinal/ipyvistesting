<!DOCTYPE html>
<html>
<head>

<title>WebGL2 volume renderer test</title>

<style>
    body {background-color: white;}
</style>


<script id="cellShader" type="glsl/vertex-shader">#version 300 es
precision highp float;
precision highp int;
precision highp sampler2D;
precision highp isampler2D;

// Contains vertex indices for each tetrahedron
uniform isampler2D u_cells;

// Contains coordinates for each vertex of the tetrahedron mesh
uniform sampler2D u_coordinates;

// Contains function values for each vertex of the tetrahedron mesh
uniform sampler2D u_functionValues;

// Camera position used to compute view direction with perspective projection
uniform vec3 u_cameraPosition;

// Camera view direction with orthographic projection
//uniform vec3 u_viewDirection;

// Cell index taken from cell ordering
in int a_cellIndex;

ivec2 texelFetchCoord(int index, ivec2 size)
{
    return ivec2(index / size.x, index % size.x);
}

void main()
{
    // Get vertex indices of cell
    ivec4 index = texelFetch(u_cells,
        texelFetchCoord(a_cellIndex, textureSize(u_cells, 0)),
        0);

    // Get vertex coordinates of cell
    ivec2 coordsTexSize = textureSize(u_coordinates, 0);
    vec3 coords[4];
    float functionValues[4];
    for (int i = 0; i < 4; ++i)
    {
        ivec2 indexPos = texelFetchCoord(index[i], coordsTexSize);
        coords[i] = texelFetch(u_coordinates, indexPos, 0).xyz;
        functionValues[i] = texelFetch(u_functionValues, indexPos, 0).x;
    }

    // Compute edge vectors
    // FIXME: Only need maybe 6 with a smarter selection,
    //        this is just a proof of concept
    vec3 e[16];
    for (int i = 0; i < 4; ++i)
    {
        for (int j = 0; j < 4; ++j)
        {
            e[i*4 + j] = coords[j] - coords[i];
        }
    }

    // Compute normals and plane equation coefficients
    // FIXME: Debug, quickly written and probably not correct
    vec4 n[4];
    for (int i = 0; i < 4; ++i)
    {
        // Indices of face i
        int i1 = (i + 1) & 3;
        int i2 = (i + 2) & 3;
        int i3 = (i + 3) & 3;

        // Face normal
        vec3 nn = normalize(cross(e[i1*4 + i2], e[i1*4 + i3]));
        nn = faceforward(nn, coords[i1] - coords[i], nn);

        // Plane equation coefficient
        n[i] = vec4(nn, dot(nn, coords[i1]));
    }

    // Compute ray length vectors holding distances from
    // each vertex to each plane along view direction,
    // only nonzero for vertex i / plane i
    vec4 t[4];
    for (int i = 0; i < 4; ++i)
    {
        // Arbitrary index on face i
        int i1 = (i + 1) & 3;

        // View direction through vertex i for perspective projected camera
        vec3 viewDirection = normalize(coords[i] - u_cameraPosition);

        // Normal of opposing face
        vec3 nn = n[i].xyz;

        // Only nonzero for vertex i -> face i
        t[i] = vec4(0.0f, 0.0f, 0.0f, 0.0f);

        // Ray length between vertex i and face i
        t[i][i] = dot(e[i*4 + i1], nn) / dot(viewDirection, nn);
    }

    // FIXME: Output cellIndex
    // FIXME: Output coords
    // FIXME: Output rayLength
    // FIXME: Output functionValue
    // FIXME: Output functionGradient
    // FIXME: Setup vertex transform buffers and test this
    // FIXME: Maybe split into more than one shader
}
</script>


<script id="vertexShader" type="glsl/vertex-shader">#version 300 es
precision highp float;
precision highp int;

// Uniforms
uniform mat4 u_mvp;   // MVP matrix
uniform sampler2D u_functionGradients;  // Function gradient for each tetrahedron

// Vertex attributes
in vec3 a_position;          // Position in model space coordinates
in vec4 a_rayLengths;        // Ray lengths to each face of tetrahedron
in int a_cellIndex;          // Tetrahedron cell index
in float a_functionValue;    // Value of function
//in vec3 a_functionGradient;  // Gradient of f on tetrahedron

// Varyings
out vec3 v_position;               // Position in model space coordinates
out vec4 v_rayLengths;             // Ray lengths to each face of tetrahedron
out float v_functionValue;         // Value of function
flat out vec3 v_functionGradient;  // Gradient of f on tetrahedron

ivec2 texelFetchCoord(int index, ivec2 size)
{
    return ivec2(index / size.x, index % size.x);
}

void main()
{
    // Pass on attributes to be interpolated across front face
    v_position = a_position;
    v_rayLengths = a_rayLengths;

    v_functionValue = a_functionValue;
    //v_functionGradient = a_functionGradient;
    v_functionGradient = texelFetch(u_functionGradients,
        texelFetchCoord(a_cellIndex, textureSize(u_functionGradients, 0)),
        0).xyz;

    // Map vertex coordinate to clip space
    gl_Position = u_mvp * vec4(a_position, 1.0);
}
</script>


<script id="fragmentShader" type="glsl/fragment-shader">#version 300 es
precision highp float;
precision highp int;
precision highp sampler2D;

// Camera position used to compute view direction with perspective projection
uniform vec3 u_cameraPosition;

// Camera view direction with orthographic projection
//uniform vec3 u_viewDirection;

// Lookup table for density
uniform sampler2D u_densityLUT;

// Lookup table for emission color
uniform sampler2D u_emissionLUT;

// Lookup table for emission color (rgb) and density (a)
//uniform sampler2D u_emissionDensityLUT

// Particle cross section to scale density with to get extinction
uniform float u_particleCrossSection;

// Min/max values of function, .x=min, .y=max, .z=1/(max-min) or 1 if equal
uniform vec3 u_functionRange;

// TODO: Get functionGradient by sampling texture instead to save memory?
//uniform sampler2D u_functionGradient;

// Varyings, interpolated on the rasterized front face currently drawn
in vec3 v_position;               // Position in model space coordinates
in vec4 v_rayLengths;             // Ray lengths to each face of tetrahedron
//flat in int v_cellIndex;          // Tetrahedron cell index
in float v_functionValue;         // Value of function
flat in vec3 v_functionGradient;  // Gradient of f on tetrahedron

// Final result
out vec4 fragColor;


vec4 integrate_constant_ray(
    float depth,
    vec3 emission,
    float extinction)
{
    // Simplest per-fragment approximation to ray integral, assuming
    // piecewise constant color and extinction across the ray segment.

    // Evaluate ray integral, use in combination
    // with blend equation: RGB_src * A_dst + RGB_dst
    float transparency = exp(-depth * extinction);
    float alpha = 1.0f - transparency;
    return vec4(alpha * emission, alpha);
}

float smallestPositive(vec4 lengths)
{
    const float infinity = 1e38;
    float depth = infinity;
    for (int i = 0; i < 4; ++i)
    {
        if (lengths[i] > 0.0f)
        {
            depth = min(depth, lengths[i]);
        }
    }
    return depth;
}

// Compute f values at entry and exit points of ray
vec2 computeFunctionValues(
    float functionValue, vec3 functionGradient,
    float depth, vec3 viewDirection)
{
    float functionDiff = depth * dot(functionGradient, viewDirection);
    return vec2(functionValue, functionValue + functionDiff);
}

// Map components of values from [range.x,range.y] to [0, 1],
// optimized by expecting range.z == 1.0f / (range.x - range.y)
vec2 mapToRange(vec2 values, vec3 range)
{
    return (values - vec2(range.x)) * range.z;
}

void main()
{
    // View direction through this fragment for perspective projected camera
    vec3 viewDirection = normalize(v_position - u_cameraPosition);

    // View direction through this fragment for orthographic projection camera
    //vec3 viewDirection = u_viewDirection;


    // Look for smallest positive ray length
    float depth = smallestPositive(v_rayLengths);

    // Compute function values at entry and exit points of ray
    vec2 f = computeFunctionValues(
        v_functionValue, v_functionGradient,
        depth, viewDirection);

    // Map function values to [0,1] range
    f = mapToRange(f, u_functionRange);


    // Use combined lookup table favg -> (emission, extinction)
    /*
    float favg = 0.5f * (f.x + f.y);

    vec4 value = texture(u_emissionDensityLUT, vec2(favg, 0.5f));
    vec3 emission = value.rgb;
    float extinction = u_particleCrossSection * value.a;

    //vec4 ee = lookup_ee(favg, u_emissionDensityLUT, u_particleCrossSection);
    */

    // Use lookup tables to map (depth, f0, f1) to extinction and emission:
    /*
    // Use combined lookup table f -> (emission, extinction)
    vec4 value0 = texture(u_emissionDensityLUT, vec2(f0, 0.5f));
    vec4 value1 = texture(u_emissionDensityLUT, vec2(f1, 0.5f));
    vec3 emission0 = value0.rgb;
    vec3 emission1 = value1.rgb;
    float extinction0 = u_particleCrossSection * value0.a;
    float extinction1 = u_particleCrossSection * value1.a;
    // Compute averages on ray segment
    vec3 emission = mix(emission0, emission1, 0.5f);
    float extinction = mix(extinction0, extinction1, 0.5f);

    //vec4 ee = lookup_ee(f, u_emissionDensityLUT, u_particleCrossSection);
    */

    // Use separate lookup tables f -> emission, g -> extinction
    ///*
    vec2 g = f;
    vec3 emission0 = texture(u_emissionLUT, vec2(f.x, 0.5f)).rgb;
    vec3 emission1 = texture(u_emissionLUT, vec2(f.y, 0.5f)).rgb;
    float extinction0 = u_particleCrossSection * texture(u_densityLUT, vec2(g.x, 0.5f)).a;
    float extinction1 = u_particleCrossSection * texture(u_densityLUT, vec2(g.y, 0.5f)).a;
    // Compute averages on ray segment
    vec3 emission = mix(emission0, emission1, 0.5f);
    float extinction = mix(extinction0, extinction1, 0.5f);

    //vec4 ee = lookup_ee(f, g, u_emissionDensityLUT, u_particleCrossSection);
    //*/


    // Alternative models:
    // - No lookup, emission and extinction both constant
    // - Lookup only emission, extinction a constant rate
    // - Lookup only extinction, emission a constant color
    // - Lookup both emission and extinction in one LUT
    // - Lookup emission and extinction in separate LUTs
    //   using separate functions: f -> emission, g -> extinction

    // Alternative LUT organization:
    // - Lookup once using favg
    //vec4 value = texture(u_emissionDensityLUT, vec2(0.5f*(f0+f1), 0.5f));
    // - Lookup at endpoints
    //vec4 value0 = texture(u_emissionDensityLUT, vec2(f0, 0.5f));
    //vec4 value1 = texture(u_emissionDensityLUT, vec2(f1, 0.5f));
    // - Lookup in 2D texture using (f0, f1)
    //vec4 value = texture(u_emissionDensityLUT, vec2(f0, f1));


    // Apply piecewise constant ray integration model
    //fragColor = integrate_constant_ray(depth, emission, extinction);
    fragColor = vec4(1.0, 0.0, 0.0, 1.0);  // Debugging: Change then vertex shader is done

    // Alternative ray models:

    // - Maximum intensity:
    //    - I(D) = f( sup_s f(s) )
    //    - Depth buffer: Off
    //    - Blend equation: Max(I_src, I_dst)
    //    - Cell ordering: No
    //    - Variants:
    //        - Direct one phase:
    //             fragColor = u_emissionColor * max(f0, f1);
    //        - Direct two phase:
    //             fragColor = max(f0, f1);
    //             Compose framebuffer with colormap in separate phase
    //        - Indirect two phase (scalar intensitymap f -> R):
    //             fragColor = max(intensitymap(f0), intensitymap(f1));
    //             Compose framebuffer with colormap in separate phase
    //        - Indirect one phase (saturates color?, colormap f -> rgb):
    //             fragColor = max(colormap(f0), colormap(f1));

    // - Splatting:
    //    - I(D) = int_0^D C(f(s)) ds
    //    - Depth buffer: Off
    //    - Blend equation: Sum(I_src, I_dst)
    //    - Cell ordering: No
    //    - fragColor = depth * texture(u_colormap, vec2(0.5f*(f0+f1), 0.5f)).rgb;

    // - Isosurfaces:
    //    - Let F = { f_i } be a discrete set of function values
    //    - Let C(f) be a colormap
    //    - Visible isosurface fragment is C(f(z)) for closest z where f(z) in F
    //         I(D) = C( f( sup_s f(s) in F ) )
    //    - "Arbitrary" number of opaque surfaces using texture:
    //         isoValue[f0,f1] = first isosurface value in [f0,f1] (closest to f0)
    //         isoColor[f0,f1] = colormap(isoValue[f0,f1])  // Precomposed
    //    - What if we want to color with another function?
    //         I(D) = C( g( sup_s f(s) in F ) )
    //         isoDist[f0,f1] = distance from f0 (z=0) towards f1 (z=1) of isoValue[f0,f1]
    //         s = isoDist[f0,f1]
    //         g = (1-s)*g0 + s*g1
    //         fragColor = colormap(g)
    //    - Depth buffer: On
    //    - Blend equation: Off
    //    - Cell ordering: No
    //    - Still need ray length to compute f1
    //    - Create texture:  u_isosurface[f0, f1] = first isosurface value in [f0,f1]
    //    - vec4 texel = texture(u_isosurface, vec2(f0, f1));
    //    - Variants:
    //        - Isosurface texture precomposed with colormap:
    //            fragColor = texel;
    //        - Compose with colormap:
    //            fragColor = texture(u_colormap, texel.x);

    // - Direct volume rendering:
    //    - T(s) = exp(-int_s^D tau rho(g(t)) dt)
    //    - I(D) = I(0) T(0) + int_0^D C(f(s)) rho(g(s)) T(s) ds
    //    - Depth buffer: Off (can use depth test to preserve opaque background)
    //    - Blend equation: (1 - A_dst) * I_src + I_dst
    //    - Cell ordering: Yes
    //    - Variants: (I), (II), (III) below

    // - (I) Fully piecewise constant emission and extinction (current)
    //   - Note: If f is also piecewise constant, don't need gradient and f0 == f1

    // - (II) Piecewise linear emission and extinction (Mooreland)

    // - (III) Arbitrary extinction transfer function with 2D texture lookup
    //   - Assuming piecewise constant C,
    //        int_0^D C rho exp(-int_s^D A rho dt) ds
    //        = C int_0^D d/ds exp(-int_s^D A rho dt) ds
    //        = C (exp(-int_D^D A rho dt) - exp(-int_0^D A rho dt))
    //        = C (1 - T)
    //        T = exp(-A int_0^D rho dt)
    //   - Using f = (1-r)f0 + r f1, r in [0,1]:
    //        r = t/D,  1-r = 1-t/D,  dr = 1/D dt,  r(t=s) = s/D,  r(t=D) = 1
    //        U = int_0^D rho(f(t)) dt
    //          = int_0^D rho( (1 - t/D)*f0 + (t/D)*f1 ) dt
    //          = D int_0^1 rho( (1-r)*f0 + r*f1 ) dr
    //   - Preintegrating R(f0,f1) = int_0^1 rho( (1-r)*f0 + r*f1 ) dr

}
</script>


<script>
function createShader(gl, type, source) {
    var shader = gl.createShader(type);
    gl.shaderSource(shader, source);
    gl.compileShader(shader);
    var success = gl.getShaderParameter(shader, gl.COMPILE_STATUS);
    if (success) {
        return shader;
    }
    var msg = gl.getShaderInfoLog(shader);
    console.log(msg);

    var elm = document.getElementById("shaderCompileErrors");
    if (!!elm) {
        elm.innerHTML = error;
    }

    gl.deleteShader(shader);
}

function createProgram(gl, vertexShader, fragmentShader) {
    var program = gl.createProgram();
    gl.attachShader(program, vertexShader);
    gl.attachShader(program, fragmentShader);
    gl.linkProgram(program);
    var success = gl.getProgramParameter(program, gl.LINK_STATUS);
    if (success) {
        return program;
    }
    var msg = gl.getProgramInfoLog(program);
    console.log(msg);
    gl.deleteProgram(program);
}
</script>


<script>

// Initial draft of a volumetric model class.
// This will need to accomodate missing cellOrdering,
// missing function values, additional function values,
// and partial updates.
function VolumeModel(vertices, cells, cellOrdering, functionValues)
{
    this.vertices = vertices,
    this.cells = cells;
    this.cellOrdering = cellOrdering;
    this.functionValues = functionValues;
    this.num_tetrahedrons = Math.floor(cells.length / 4);
    this.num_vertices = Math.floor(vertices.length / 3);

    var num_triangle_vertices = this.num_tetrahedrons * 4;
    if (cells.length !== 4 * this.num_tetrahedrons) {
        throw "Invalid dimensions.";
    }
    if (vertices.length !== 3 * this.num_vertices) {
        throw "Invalid dimensions.";
    }
    if (cellOrdering.length !== this.num_tetrahedrons) {
        throw "Invalid dimensions.";
    }
    if (functionValues.length !== this.num_vertices) {
        throw "Invalid dimensions.";
    }
}

// Create test model with unstructured tetrahedral mesh data
function createTestModel() {
    var vertices = new Float32Array([
        0.0, 0.0, 0.0,
        0.0, 0.0, 1.0,
        0.0, 1.0, 0.0,
        1.0, 0.0, 0.0,
        1.0, 1.0, 1.0,
    ]);
    var cells = new Uint32Array([
        0, 1, 2, 3,
        1, 2, 3, 4,
    ]);
    var cellOrdering = new Uint32Array([
        1, 0
    ]);
    var functionValues = new Float32Array([
        1.0, 2.0, 3.0, 4.0, 5.0
    ]);
    return new VolumeModel(vertices, cells, cellOrdering, functionValues);
}

function ModelBuffers(model) {
    this.model = model;
}

function setupCellShaderInputs() {
    // FIXME: Setup cell shader uniforms and attributes:
}

function setupVertexShaderInputs() {
/*  FIXME: Setup vertex shader uniforms and attributes:
uniform sampler2D u_functionGradients;  // Function gradient for each tetrahedron

// Vertex attributes
in vec3 a_position;          // Position in model space coordinates
in vec4 a_rayLengths;        // Ray lengths to each face of tetrahedron
in int a_cellIndex;          // Tetrahedron cell index
in float a_functionValue;    // Value of function
//in vec3 a_functionGradient;  // Gradient of f on tetrahedron
*/
}

</script>


<script>

var DEBUG = true;

var canvas;
var gl;
var volren;


// Generate set of shaders  // TODO: Allow configuration
function generateShaders() {
    var cellShaderSrc = document.getElementById("cellShader").innerHTML;
    var vertexShaderSrc = document.getElementById("vertexShader").innerHTML;
    var fragmentShaderSrc = document.getElementById("fragmentShader").innerHTML;

    return {
        cellShaderSrc: cellShaderSrc,
        vertexShaderSrc: vertexShaderSrc,
        fragmentShaderSrc: fragmentShaderSrc
    };
}


// Compile shaders and link programs
function compilePrograms(gl, shaders) {
    var cellShader = createShader(gl, gl.VERTEX_SHADER, shaders.cellShaderSrc);
    var cellProgram = 0; //createProgram(gl, cellShader, ...);

    var vertexShader = createShader(gl, gl.VERTEX_SHADER, shaders.vertexShaderSrc);
    var fragmentShader = createShader(gl, gl.FRAGMENT_SHADER, shaders.fragmentShaderSrc);
    var vertexProgram = createProgram(gl, vertexShader, fragmentShader);

    return {
        cellProgram: cellProgram,
        vertexProgram: vertexProgram
    };
}

// Mirror of THREE.BufferAttribute
function BufferAttribute(array, itemSize)
{
    this.array = array;
    this.count = array.length / itemSize;
    this.itemSize = itemSize;
    this.dynamic = false;
}

function setup(gl) {

    // Configure size and background
    //webglUtils.resizeCanvasToDisplaySize(gl.canvas);
    gl.viewport(0, 0, gl.canvas.width, gl.canvas.height);
    gl.clearColor(0, 0, 0, 0);

    // Generate shader sources
    var shaders = generateShaders();

    // Compile programs
    var programs = compilePrograms(gl, shaders);

    // Create VAOs for each program
    var vaos = {
        cellVao: gl.createVertexArray(),
        vertexVao: gl.createVertexArray()
    };

    // Create some test data
    var model = createTestModel();

    // Collect state in global volren object
    // (for now, figure out better design later)
    volren = {}
    volren.gl = gl;
    volren.programs = programs;
    volren.vaos = vaos;
    volren.model = model;
    volren.config = { rayModel: "dvr" };


    ///////////////////////////////////////////////////////////////////////////
    /* Things to do:

    - Upload vertices to buffer
    - Upload cells to buffer
    - Upload ordering to buffer
    - Upload vertexvalues to buffer

    - Allocate buffer for float functionValue per vert per cell
    - Allocate buffer for vec3 functionGradient per cell (use as texture) or per vert per cell (use as vba)
    - Allocate buffer for vec4 rayLength per vert per cell
    - Allocate buffer for uint cellIndex per vert per cell (duplicated from cellOrdering)
    - Allocate buffer for vec3 position per vert per cell
    */
    // Attribute dimensions:
    /*
    gl.vertexAttribPointer(functionValueLoc, 1, gl.FLOAT, false, 0, 0);
    gl.vertexAttribPointer(functionGradientLoc, 3, gl.FLOAT, false, 0, 0);
    gl.vertexAttribPointer(rayLengthLoc, 4, gl.FLOAT, false, 0, 0);
    gl.vertexAttribPointer(cellIndexLoc, 1, gl.UINT, false, 0, 0);
    gl.vertexAttribPointer(positionLoc, 3, gl.FLOAT, false, 0, 0);
    */
    ///////////////////////////////////////////////////////////////////////////


    //gl.useProgram(volren.programs.cellProgram);
    //gl.bindVertexArray(volren.vaos.cellVao);

    // Select program and vao
    var program = volren.programs.vertexProgram;
    var vao = volren.vaos.vertexVao;
    gl.useProgram(program);
    gl.bindVertexArray(vao);

    // Upload uniform values
    var mvp = new Float32Array([
        1.0, 0.0, 0.0, 0.0,
        0.0, 1.0, 0.0, 0.0,
        0.0, 0.0, 1.0, 0.0,
        0.0, 0.0, 0.0, 1.0,
    ]);
    var mvpLocation = gl.getUniformLocation(program, "u_mvp");
    gl.uniformMatrix4fv(mvpLocation, false, mvp);

    var backgroundColor = new Float32Array([1.0, 1.0, 0.0, 1.0]);
    var backgroundColorLocation = gl.getUniformLocation(program, "u_backgroundColor");
    gl.uniform4fv(backgroundColorLocation, backgroundColor);


    // Configure and upload attribute arrays
    var positions = new Float32Array([
        0, 0,
        0, 0.8,
        0.4, 0,
    ]);
    var positionBuffer = gl.createBuffer();
    gl.bindBuffer(gl.ARRAY_BUFFER, positionBuffer);
    gl.bufferData(gl.ARRAY_BUFFER, positions, gl.STATIC_DRAW);

    var positionAttributeLocation = gl.getAttribLocation(program, "a_position");
    gl.enableVertexAttribArray(positionAttributeLocation);
    gl.vertexAttribPointer(positionAttributeLocation,
        2, gl.FLOAT, false, 0, 0);
}

function configureBlendEquation(gl, rayModel) {
    switch (rayModel)
    {
    case "dvr":
        gl.blendEquation(gl.FUNC_ADD);
        gl.blendFunc(gl.ONE_MINUS_DST_ALPHA, gl.ONE);
        break;
    case "sum":
        gl.blendEquation(gl.FUNC_ADD);
        gl.blendFunc(gl.ONE, gl.ONE);
        break;
    case "max":
        gl.blendEquation(gl.MAX);
        break;
    case "min":
        gl.blendEquation(gl.MIN);
        break;
    default:
        console.log("Unknown ray model " + rayModel);
    }
}

function render(volren) {
    gl = volren.gl;

    // Process tetrahedron cells
    //gl.useProgram(volren.programs.cellProgram);
    //gl.bindVertexArray(volren.vaos.cellVao);
    //gl.drawArrays(gl.POINTS, 0, volren.model.num_tetrahedrons);

    // Draw triangles
    gl.useProgram(volren.programs.vertexProgram);
    gl.bindVertexArray(volren.vaos.vertexVao);
    configureBlendEquation(gl, volren.config.rayModel);
    gl.clear(gl.COLOR_BUFFER_BIT);
    gl.drawArrays(gl.TRIANGLES, 0, 3);//4 * volren.model.num_tetrahedrons);
}

function update() {
    // Using global object volren
    //window.requestAnimationFrame(update);
    render(volren);
}

function init()
{
    var canvas = document.getElementById("webgl2canvas");
    var gl = canvas.getContext("webgl2", {
        antialias: false,
        depth: false,
        alpha: true,
        stencil: false,
        preserveDrawingBuffer: true,
        failIfMajorPerformanceCaveat: true,
    });
    if (!gl) {
        console.log("Failed to get webGL2 context.");
        return;
    }

    // Initial gl setup
    setup(gl);

    // Start updates
    update();
}
</script>

</head>
<body onload="init();">
    <canvas id="webgl2canvas" width="800" height="600"></canvas>
    <div id="shaderdisplay">
        <h3>shader compile/link errors</h3>
        <pre><code id="shaderCompileErrors">No errors.</code></pre>
    </div>
</body>
</html>